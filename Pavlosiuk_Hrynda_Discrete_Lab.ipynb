{"cells":[{"cell_type":"markdown","metadata":{"id":"TUMlYqj3oKCC"},"source":["s## Лабораторна робота №2: \"Імплементація алгоритмів стиснення\"\n","\n","Склад команди та розподіл виконаних завдань:\n","\n","- Гринда Юліана\n","- Павлосюк Роман\n","\n","Для кожного з алгоритмів поданих нижче\n","- опишіть як працює алгорит\n","- напишіть класи з методами encode та decode\n","- перевірте правильність кодування та декодування\n","- дослідіть час виконання коду в залежності від розмірів вхідних даних\n","- оцініть ступінь стиснення(у відсотка) в залежності від розмірів\n","- напишіть висновок про ефективність різних алгоритмів та умови за яких той чи інший алгоритм дають кращий результат"]},{"cell_type":"markdown","metadata":{"id":"q7FpJG25oNzA"},"source":["# Алгоритм Гаффмана\n","\n","В цьому алгоритмі доцільно імплементувати клас node та додаткові функції в Huffman для побудови дерева кодування"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fHzFB9gh7c2"},"outputs":[],"source":["class Node:\n","    def __init__(self, char, freq):\n","        self.char = char\n","        self.freq = freq\n","        self.left = None\n","        self.right = None\n","\n","    def __repr__(self) -> str:\n","        return f'{self.char}: {self.freq}'\n","\n","class Huffman:\n","    def encode(self, text: str) -> tuple[str, dict[str, str]]:\n","        letters = {letter: '' for letter in text}\n","        nodes = sorted([Node(letter, text.count(letter) /\n","                             len(text)) for letter in letters], key = lambda x: x.freq)\n","        tree = self.build_tree(nodes)\n","        alphabet = self.alphabet_code(tree, letters)\n","        result = ''\n","        for char in text:\n","            result += alphabet[char]\n","        return (result, alphabet)\n","    \n","    def build_tree(self, nodes):\n","        while len(nodes) > 1:\n","            left_node = nodes.pop(0)\n","            right_node = nodes.pop(0)\n","            parent_node = Node(None, left_node.freq + right_node.freq)\n","            parent_node.left = left_node\n","            parent_node.right = right_node\n","            nodes.append(parent_node)\n","            nodes = sorted(nodes, key = lambda x: x.freq)\n","\n","        return nodes[0]\n","\n","    def alphabet_code(self, node, letters, code = ''):\n","        if not node.char is None:\n","            letters[node.char] = code\n","        else:\n","            for i in range(2):\n","                if i == 0:\n","                    code_ = code + '0'\n","                    self.alphabet_code(node.left, letters, code_)\n","                else:\n","                    code_ = code + '1'\n","                    self.alphabet_code(node.right, letters, code_)\n","        return letters\n","\n","    def decode(self, code: str, coding_dict: dict[str, str]):\n","        coding_dict = {value: key for key, value in coding_dict.items()}\n","        result = ''\n","        match_ = ''\n","        for char in code:\n","            if match_ + char in coding_dict:\n","                result += coding_dict[match_ + char]\n","                match_ = ''\n","            else:\n","                match_ += char\n","        return result\n"]},{"cell_type":"markdown","metadata":{"id":"6_0LIrbWoQxo"},"source":["# Алгоритм LZW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ogew0FkaoUNS"},"outputs":[],"source":["class LZW:\n","    def encode(self, text:str) -> tuple[str, list]:\n","        '''LZW encoding'''\n","        output = []\n","        w = ''\n","        start_dictionary = {}\n","        counter = 0\n","        for letter in text:\n","            if letter not in start_dictionary:\n","                start_dictionary[letter] = counter\n","                counter += 1\n","        new_dictionary = start_dictionary.copy()\n","        for letter in text:\n","            if w + letter in new_dictionary:\n","                w += letter\n","            else:\n","                new_dictionary.update({w + letter: max(new_dictionary.values())+1})\n","                output.append(new_dictionary[w])\n","                w = letter\n","        output.append(new_dictionary[w])\n","        return output, list(start_dictionary.keys())\n","\n","    def decode(self, code: list, coding_dict: list) -> str:\n","        '''LZW decoding'''\n","        coding_dict = {i:el for i,el in enumerate(coding_dict)}\n","        string = coding_dict[code[0]]\n","        output = ''\n","        output += string\n","        counter = max(coding_dict.keys()) + 1\n","        for i in range(len(code)-1):\n","            new = code[i + 1]\n","            if new not in coding_dict:\n","                entry = string + string[0]\n","            else:\n","                entry = coding_dict[new]\n","            output += entry\n","            coding_dict[counter] = string + entry[0]\n","            counter += 1\n","            string = entry\n","        return output\n"]},{"cell_type":"markdown","metadata":{"id":"eETQbkkDoTDc"},"source":["# Алгоритм LZ77\n","\n","Потрібно заміряти розміри саме тексту, проте для роботи доцільно використовувати список тюплів, тому для зручності варто імплементувати додаткові алгоритми _text2list та _list2text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mu1A0QS2oaOF"},"outputs":[],"source":["class LZ77:\n","    def __init__(self, buffer_size: int):\n","        self.buffer_size = buffer_size\n","\n","    def encode(self, text: str) -> str:\n","        encoded_data = []\n","        current_index = 0\n","\n","        while current_index < len(text):\n","            best_offset = -1\n","            best_length = -1\n","            best_match = ''\n","\n","            for length in range(1, min(len(text) - current_index, self.buffer_size)):\n","                sub_data = text[current_index:current_index + length]\n","                offset = text.rfind(sub_data, max(0, current_index - self.buffer_size), current_index)\n","\n","                if offset != -1 and length > best_length:\n","                    best_offset = current_index - offset\n","                    best_length = length\n","                    best_match = sub_data\n","\n","            if best_match:\n","                encoded_data.append((best_offset, best_length, text[current_index + best_length]))\n","                current_index += best_length + 1\n","            else:\n","                encoded_data.append((0, 0, text[current_index]))\n","                current_index += 1\n","\n","        return encoded_data\n","\n","    def decode(self, code: str) -> str:\n","        decoded_data = []\n","\n","        for item in code:\n","            offset, length, code_word = item\n","\n","            if not length:\n","                decoded_data.append(code_word)\n","            else:\n","                start = len(decoded_data) - offset\n","                substring = decoded_data[start:start + length]\n","                decoded_data.extend(substring)\n","                decoded_data.append(code_word)\n","\n","        return ''.join(decoded_data)"]},{"cell_type":"markdown","metadata":{"id":"bz-B5jWroghO"},"source":["# Алгоритм Deflate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAU57ZQtogOC"},"outputs":[],"source":["class Deflate:\n","    def __init__(self, buffer_size: int):\n","        pass\n","\n","    def encode(self, text: str) -> str:\n","        pass\n","\n","    def decode(self, code: str) -> str:\n","        pass"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPfU8BzBRTPt6lIw6h6vnIC","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
